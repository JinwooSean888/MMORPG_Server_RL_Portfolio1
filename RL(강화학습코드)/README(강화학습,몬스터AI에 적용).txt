## Reinforcement Learning (Monster AI Prototype)

본 프로젝트에는 강화학습 기반 몬스터 AI 프로토타입이 포함되어 있습니다.  
강화학습은 게임 서버 구조와의 결합 가능성 검증을 목적으로 도입되었습니다.

> 목표:  
> 서버 권한 구조를 유지한 상태에서  
> FSM을 대체하거나 보완할 수 있는 AI 제어 방식 실험

---

### Overview

- 알고리즘: PPO (Proximal Policy Optimization)
- 프레임워크: PyTorch
- 학습환경 : VS CODE
- 학습 대상: 몬스터 이동 / 추적 / 공격 행동
- 환경: 서버 로직을 단순화한 Grid 기반 시뮬레이션 환경

강화학습 모델은 실시간 추론용이 아닌 오프라인 학습 결과로 사용되며,  
학습된 정책 결과를 서버 로직에 반영하는 구조를 실험했습니다.

---

### Server-Oriented Design Considerations

강화학습 적용 시 아래와 같은 서버 관점의 제약 조건을 고려했습니다.

- 서버 권한 구조 유지 (클라이언트 의존 X)
- Tick 기반 업데이트 모델과의 호환
- 다수 몬스터 동시 처리 시 성능 영향 최소화
- FSM 대비 장단점 비교 가능 구조

이로 인해, 학습 환경과 실제 서버 로직은 명확히 분리되어 있습니다.

---

### Integration Strategy (Prototype)

- 학습 단계:
  - Python 환경에서 몬스터 행동 정책 학습
  - 서버 로직과 동일한 상태 변수 사용 (거리, 방향, HP 등)

- 적용 단계:
  - 학습 결과를 기반으로 행동 선택 로직을 서버에 반영
  - 기존 FSM과 병행 가능하도록 설계

> 현재 공개 저장소에는 학습 코드 및 실험용 환경 일부만 포함되어 있으며,  
> 실제 서비스 적용을 전제로 한 최적화 및 튜닝은 제외되어 있습니다.

---

### Notes

- 본 강화학습 구현은 게임 AI 연구 목적의 프로토타입입니다.
- 대규모 상용 서버 적용 시에는 FSM/ECS 기반 구조와의 혼합 방식이 더 현실적이라고 판단하고 있습니다.